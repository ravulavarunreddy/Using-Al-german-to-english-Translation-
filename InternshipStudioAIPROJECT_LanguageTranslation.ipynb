{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLchsbOh4f4q"
   },
   "source": [
    "**IMPORTING REQUIRED LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DYJ_M2Sa9Fqn"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ijh8LcoR47qS"
   },
   "source": [
    "**The data is a text file (.txt) of English-German sentence pairs. We have to read the file first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "txkN0Xne9Sew"
   },
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "        # open the file\n",
    "        file = open(filename, mode='rt', encoding='utf-8')\n",
    "        \n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeQGcru65DF_"
   },
   "source": [
    "**Another function is defined to split the text into English-German pairs. Then we split these pairs into English sentences and German sentences respectively.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "krnnX0DW9Ww7"
   },
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "      sents = text.strip().split('\\n')\n",
    "      sents = [i.split('\\t') for i in sents]\n",
    "      return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OQwW07l5XtJ"
   },
   "source": [
    "**We can use the below functions to read the text into an array in our desired format.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SReZEWrK9Yy5"
   },
   "outputs": [],
   "source": [
    "data = read_text(\"deu.txt\")\n",
    "deu_eng = to_lines(data)\n",
    "deu_eng = array(deu_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RU5h7QW5dfV"
   },
   "source": [
    "**The actual data contains over 150,000 sentence-pairs. \n",
    "However, we will use only the first 50,000 sentence pairs to reduce the training time of the model.\n",
    "This number can be changes as per system's computation power.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Jmd_pYhm9bTF"
   },
   "outputs": [],
   "source": [
    "deu_eng = deu_eng[:50000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQDTVbwg5jXS"
   },
   "source": [
    "**Text Pre-Processing**\n",
    "Quite an important step in any project, especially so in NLP. The data we work with is more often than not unstructured so there are certain things we need to take care of before jumping to the model building part.\n",
    "\n",
    "**(a) Text Cleaning**\n",
    "\n",
    "Let’s first take a look at our data. This will help us decide which pre-processing steps to adopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrZitFVb9ib3",
    "outputId": "79d90744-3d6c-499e-8716-b6732edc11ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go.', 'Geh.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
       "       ['Hi.', 'Hallo!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
       "       ['Hi.', 'Grüß Gott!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
       "       ...,\n",
       "       ['We took a wrong turn.', 'Wir sind falsch abgebogen.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #823901 (jellorage) & #2112094 (freddy1)'],\n",
       "       ['We traveled together.', 'Wir waren zusammen auf Reisen.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600396 (Pfirsichbaeumchen)'],\n",
       "       ['We traveled together.', 'Wir sind zusammen gereist.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600398 (Pfirsichbaeumchen)']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SKYrjGu50KW"
   },
   "source": [
    "**Now get rid of the punctuation marks and then convert all the text to lower case.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vCKL4nV9maL",
    "outputId": "d6f4df12-e768-4723-f223-791be85105f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go', 'Geh',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
       "       ['Hi', 'Hallo',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
       "       ['Hi', 'Grüß Gott',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
       "       ...,\n",
       "       ['We took a wrong turn', 'Wir sind falsch abgebogen',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #823901 (jellorage) & #2112094 (freddy1)'],\n",
       "       ['We traveled together', 'Wir waren zusammen auf Reisen',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600396 (Pfirsichbaeumchen)'],\n",
       "       ['We traveled together', 'Wir sind zusammen gereist',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600398 (Pfirsichbaeumchen)']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
    "\n",
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RI0YicaH9kWt",
    "outputId": "cb1d1fec-023e-4c69-b952-376c5b0b7e4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['go', 'geh',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
       "       ['hi', 'hallo',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
       "       ['hi', 'grüß gott',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
       "       ...,\n",
       "       ['we took a wrong turn', 'wir sind falsch abgebogen',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #823901 (jellorage) & #2112094 (freddy1)'],\n",
       "       ['we traveled together', 'wir waren zusammen auf reisen',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600396 (Pfirsichbaeumchen)'],\n",
       "       ['we traveled together', 'wir sind zusammen gereist',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1582121 (Spamster) & #1600398 (Pfirsichbaeumchen)']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert text to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()\n",
    "\n",
    "deu_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Svg4MUz6Ba7"
   },
   "source": [
    "**(b) Text to Sequence Conversion**\n",
    "\n",
    "A Seq2Seq model requires that we convert both the input and the output sentences into integer sequences of fixed length.\n",
    "\n",
    "But before we do that, let’s visualise the length of the sentences. We will capture the lengths of all the sentences in two separate lists for English and German, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "EBqfxOq69syL",
    "outputId": "850a7490-5e2e-403c-8bcd-e0ab39c4d936"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "      eng_l.append(len(i.split()))\n",
    "\n",
    "for i in deu_eng[:,1]:\n",
    "      deu_l.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGCLPQid6McH"
   },
   "source": [
    "**Quite intuitive** – the maximum length of the German sentences is 11 and that of the English phrases is 8.\n",
    "\n",
    "Next, vectorize our text data by using **Keras’s Tokenizer() class**. It will turn our sentences into sequences of integers. We can then pad those sequences with zeros to make all the sequences of the same length.\n",
    "\n",
    "Note that **we will prepare tokenizers for both the German and English sentences:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RKn8J4FG9wY2"
   },
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "      tokenizer = Tokenizer()\n",
    "      tokenizer.fit_on_texts(lines)\n",
    "      return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDJ5LbgL9yil",
    "outputId": "9914f03d-24f9-4566-e06b-b31214f8ba08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 6152\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpCx4qU590N9",
    "outputId": "28d0e0f8-bada-4052-c3fc-467a6522a727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 10112\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 8\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ys9UvEu6Y7U"
   },
   "source": [
    "**The below code block contains a function to prepare the sequences. It will also perform sequence padding to a maximum sentence length as mentioned above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-ePjxaBV92vI"
   },
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "         # integer encode sequences\n",
    "         seq = tokenizer.texts_to_sequences(lines)\n",
    "         # pad sequences with 0 values\n",
    "         seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "         return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTKveeeo6e85"
   },
   "source": [
    "**Model Building**\n",
    "We will now split the data into train and test set for model training and evaluation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PI7Go0NW94vb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test set\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgKbX-LQ6mVj"
   },
   "source": [
    "It’s time to encode the sentences. We will encode **German sentences as the input sequences** and **English sentences as the target sequences**. This has to be done for both the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qcBiiQBE96n0"
   },
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "\n",
    "# prepare validation data\n",
    "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-Rx9MVv6vxz"
   },
   "source": [
    "Now we’ll start off by defining our Seq2Seq model architecture:\n",
    "\n",
    "For the encoder, we will use an embedding layer and an LSTM layer\n",
    "For the decoder, we will use another LSTM layer followed by a dense layer\n",
    "Encoder Decoder model architecture\n",
    "\n",
    "\n",
    "**Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ipKjtBoK98c_"
   },
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
    "      model = Sequential()\n",
    "      model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "      model.add(LSTM(units))\n",
    "      model.add(RepeatVector(out_timesteps))\n",
    "      model.add(LSTM(units, return_sequences=True))\n",
    "      model.add(Dense(out_vocab, activation='softmax'))\n",
    "      return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iY9bvNGQ67SS"
   },
   "source": [
    "**We are using the RMSprop optimizer in this model as it’s usually a good choice when working with recurrent neural networks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DhLo4r-h9_Iy"
   },
   "outputs": [],
   "source": [
    "# model compilation\n",
    "model = define_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLfdmsv6-BQd",
    "outputId": "538d4d9f-9e36-47b3-dd5d-59217ad4eef4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_czN0Asu6-_U"
   },
   "source": [
    "Please note that we have used **‘sparse_categorical_crossentropy‘** as the loss function. This is because the function allows us to use the target sequence as is, instead of the one-hot encoded format. One-hot encoding the target sequences using such a huge vocabulary might consume our system’s entire memory.\n",
    "\n",
    "We are all set to start training our model!\n",
    "\n",
    "We will train it for **30 epochs and with a batch size of 512 with a validation split of 20%**. 80% of the data will be used for training the model and the rest for evaluating it. You may change and play around with these hyperparameters.\n",
    "\n",
    "We will also use the **ModelCheckpoint()** function to save the model with the lowest validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odsfvv4t-DHI",
    "outputId": "bd2a67d1-80f1-453a-c710-7f9b8839a259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - 184s 3s/step - loss: 4.2993 - val_loss: 2.7590\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.75903, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "63/63 [==============================] - 161s 3s/step - loss: 2.7220 - val_loss: 2.7022\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.75903 to 2.70216, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "63/63 [==============================] - 160s 3s/step - loss: 2.5671 - val_loss: 2.5826\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.70216 to 2.58257, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "63/63 [==============================] - 161s 3s/step - loss: 2.3804 - val_loss: 2.3823\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.58257 to 2.38229, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "63/63 [==============================] - 160s 3s/step - loss: 2.2286 - val_loss: 2.2489\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.38229 to 2.24890, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "63/63 [==============================] - 159s 3s/step - loss: 2.0912 - val_loss: 2.1281\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.24890 to 2.12805, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "63/63 [==============================] - 159s 3s/step - loss: 1.9432 - val_loss: 2.0397\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.12805 to 2.03967, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "63/63 [==============================] - 159s 3s/step - loss: 1.8263 - val_loss: 1.9648\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.03967 to 1.96483, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "63/63 [==============================] - 158s 3s/step - loss: 1.7133 - val_loss: 1.8835\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.96483 to 1.88353, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "63/63 [==============================] - 158s 3s/step - loss: 1.6083 - val_loss: 1.8054\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.88353 to 1.80543, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "63/63 [==============================] - 158s 3s/step - loss: 1.5101 - val_loss: 1.7564\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.80543 to 1.75641, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "63/63 [==============================] - 162s 3s/step - loss: 1.4186 - val_loss: 1.6947\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.75641 to 1.69469, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "63/63 [==============================] - 161s 3s/step - loss: 1.3162 - val_loss: 1.6454\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.69469 to 1.64542, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "63/63 [==============================] - 160s 3s/step - loss: 1.2438 - val_loss: 1.5980\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.64542 to 1.59800, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "63/63 [==============================] - 159s 3s/step - loss: 1.1693 - val_loss: 1.5559\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.59800 to 1.55593, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "63/63 [==============================] - 159s 3s/step - loss: 1.0836 - val_loss: 1.5029\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.55593 to 1.50288, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "63/63 [==============================] - 158s 3s/step - loss: 1.0131 - val_loss: 1.4874\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.50288 to 1.48740, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "63/63 [==============================] - 158s 3s/step - loss: 0.9444 - val_loss: 1.4372\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.48740 to 1.43721, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "63/63 [==============================] - 161s 3s/step - loss: 0.8788 - val_loss: 1.4151\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.43721 to 1.41506, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "63/63 [==============================] - 160s 3s/step - loss: 0.8108 - val_loss: 1.3816\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.41506 to 1.38161, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "63/63 [==============================] - 159s 3s/step - loss: 0.7553 - val_loss: 1.3493\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.38161 to 1.34934, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "63/63 [==============================] - 159s 3s/step - loss: 0.6995 - val_loss: 1.3352\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.34934 to 1.33516, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "63/63 [==============================] - 161s 3s/step - loss: 0.6422 - val_loss: 1.3164\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.33516 to 1.31640, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "63/63 [==============================] - 159s 3s/step - loss: 0.5992 - val_loss: 1.3018\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.31640 to 1.30175, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "63/63 [==============================] - 160s 3s/step - loss: 0.5453 - val_loss: 1.2860\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.30175 to 1.28597, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "63/63 [==============================] - 165s 3s/step - loss: 0.5060 - val_loss: 1.2837\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.28597 to 1.28372, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "63/63 [==============================] - 163s 3s/step - loss: 0.4626 - val_loss: 1.2681\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.28372 to 1.26815, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "63/63 [==============================] - 162s 3s/step - loss: 0.4263 - val_loss: 1.2685\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.26815\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 162s 3s/step - loss: 0.3830 - val_loss: 1.2555\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.26815 to 1.25552, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "63/63 [==============================] - 161s 3s/step - loss: 0.3531 - val_loss: 1.2526\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.25552 to 1.25259, saving model to model.h1.30_july_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.h1.30_july_21/assets\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h1.30_july_21'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# train model\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
    "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq4TY5yf7VL5"
   },
   "source": [
    "Let’s compare the training loss and the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "UqSehCiT-KMf",
    "outputId": "00097d14-dd18-4007-acdd-a8f70e7b73bc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWASbCTq7cDO"
   },
   "source": [
    "As you can see in the above plot, the validation loss stopped decreasing after 20 epochs.\n",
    "\n",
    "Finally, we can load the saved model and make predictions on the unseen data – testX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2DYiktY-L_M",
    "outputId": "bf79bf1a-9160-4411-d43f-81bb24d2d247"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h1.30_july_21')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqJ_Bq-w7fBI"
   },
   "source": [
    "These predictions are sequences of integers. We need to convert these integers to their corresponding words. Let’s define a function to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BNNYqH5J-Rh7"
   },
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "      for word, index in tokenizer.word_index.items():\n",
    "          if index == n:\n",
    "              return word\n",
    "      return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eDk5N-87jQw"
   },
   "source": [
    "Convert predictions into text (English):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8k8CVSjL-Tjc"
   },
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds:\n",
    "       temp = []\n",
    "       for j in range(len(i)):\n",
    "            t = get_word(i[j], eng_tokenizer)\n",
    "            if j > 0:\n",
    "                if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                     temp.append('')\n",
    "                else:\n",
    "                     temp.append(t)\n",
    "            else:\n",
    "                   if(t == None):\n",
    "                          temp.append('')\n",
    "                   else:\n",
    "                          temp.append(t) \n",
    "\n",
    "       preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mc3dUFLp7ncB"
   },
   "source": [
    "Let’s put the original English sentences in the test dataset and the predicted sentences in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "mG8YlrVr-XOD"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSM_NCVW7vXS"
   },
   "source": [
    "We can randomly print some actual vs predicted instances to see how our model performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oMj6WErxdYfH"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "Wf3s5q4G-ZHz",
    "outputId": "d7333836-673c-450e-e457-58610cf9f4db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>it wont work</td>\n",
       "      <td>that doesnt work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>i want you to stop</td>\n",
       "      <td>i want you to stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>its a beautiful day</td>\n",
       "      <td>its a nice day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>have a beer with me</td>\n",
       "      <td>have a drink beer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5926</th>\n",
       "      <td>tom was married</td>\n",
       "      <td>tom was married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>she gets up early</td>\n",
       "      <td>theyre up early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>tom didnt agree</td>\n",
       "      <td>tom wasnt notice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7429</th>\n",
       "      <td>roses are beautiful</td>\n",
       "      <td>cats are smart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>were on your side</td>\n",
       "      <td>were on your side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>please step aside</td>\n",
       "      <td>please step aside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9068</th>\n",
       "      <td>i need a new car</td>\n",
       "      <td>i need a new car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>tom is careless</td>\n",
       "      <td>tom is very</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9195</th>\n",
       "      <td>im a student here</td>\n",
       "      <td>im am here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>tom was fighting</td>\n",
       "      <td>tom prayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>i cant play piano</td>\n",
       "      <td>i cant play chicken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   actual                predicted\n",
       "15           it wont work    that doesnt work     \n",
       "5908   i want you to stop    i want you to stop   \n",
       "6442  its a beautiful day       its a nice day    \n",
       "4751  have a beer with me    have a drink beer    \n",
       "5926      tom was married     tom was married     \n",
       "3201    she gets up early     theyre up early     \n",
       "3741      tom didnt agree    tom wasnt notice     \n",
       "7429  roses are beautiful      cats are smart     \n",
       "4356    were on your side    were on your side    \n",
       "485     please step aside   please step aside     \n",
       "9068     i need a new car      i need a new car   \n",
       "7217      tom is careless         tom is very     \n",
       "9195    im a student here          im am here     \n",
       "253      tom was fighting         tom prayed      \n",
       "1180    i cant play piano  i cant play chicken    "
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 15 rows randomly\n",
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "bcoh1dBbdoks",
    "outputId": "d67aa6da-07d5-45c6-f541-8b934e22e58e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the number</td>\n",
       "      <td>whats the number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>try it on</td>\n",
       "      <td>try it on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we were wrong</td>\n",
       "      <td>we were wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thats untrue</td>\n",
       "      <td>this not right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dont touch anything</td>\n",
       "      <td>dont touch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tom is calling back</td>\n",
       "      <td>tom will back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i think tom is awake</td>\n",
       "      <td>i think tom is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what are you having</td>\n",
       "      <td>what can it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i like that flag</td>\n",
       "      <td>i like this flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you have a good job</td>\n",
       "      <td>you have a good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i was at home</td>\n",
       "      <td>i was home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>im a monk</td>\n",
       "      <td>i am a monk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>did i ask you</td>\n",
       "      <td>did i you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>are you angry</td>\n",
       "      <td>are you mad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tom is generous</td>\n",
       "      <td>tom is generous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  actual              predicted\n",
       "0     what is the number  whats the number     \n",
       "1              try it on         try it on     \n",
       "2          we were wrong     we were wrong     \n",
       "3           thats untrue    this not right     \n",
       "4    dont touch anything       dont touch      \n",
       "5    tom is calling back     tom will back     \n",
       "6   i think tom is awake     i think tom is    \n",
       "7    what are you having       what can it     \n",
       "8       i like that flag   i like this flag    \n",
       "9    you have a good job    you have a good    \n",
       "10         i was at home        i was home     \n",
       "11             im a monk        i am a monk    \n",
       "12         did i ask you         did i you     \n",
       "13         are you angry       are you mad     \n",
       "14       tom is generous   tom is generous     "
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "CjgYmVkVdsFu",
    "outputId": "93cc342e-5881-4020-8d26-24aa749c6094"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>i saw you looking</td>\n",
       "      <td>i saw you before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>tom was so busy</td>\n",
       "      <td>tom was that night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>where could he be</td>\n",
       "      <td>where did he be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>my friend was shot</td>\n",
       "      <td>my hair was very</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>come on trust me</td>\n",
       "      <td>come and help me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>life is too short</td>\n",
       "      <td>life is too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>everybody saw it</td>\n",
       "      <td>everyone saw it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>try harder</td>\n",
       "      <td>try harder next</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>he will be punished</td>\n",
       "      <td>he is be urgent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>i speak swedish</td>\n",
       "      <td>i will dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>have fun you guys</td>\n",
       "      <td>have a great weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>give tom my thanks</td>\n",
       "      <td>take with for me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>do what you must</td>\n",
       "      <td>dont do you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>tom combed his hair</td>\n",
       "      <td>tom exhaled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>is this car yours</td>\n",
       "      <td>is this your car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   actual                 predicted\n",
       "9985    i saw you looking      i saw you before    \n",
       "9986      tom was so busy    tom was that night    \n",
       "9987    where could he be       where did he be    \n",
       "9988   my friend was shot      my hair was very    \n",
       "9989     come on trust me      come and help me    \n",
       "9990    life is too short          life is too     \n",
       "9991     everybody saw it      everyone saw it     \n",
       "9992           try harder      try harder next     \n",
       "9993  he will be punished       he is be urgent    \n",
       "9994      i speak swedish         i will dance     \n",
       "9995    have fun you guys  have a great weekend    \n",
       "9996   give tom my thanks      take with for me    \n",
       "9997     do what you must          dont do you     \n",
       "9998  tom combed his hair         tom exhaled      \n",
       "9999    is this car yours      is this your car    "
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5VuyeuyYCsQ"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "InternshipStudio_LanguageTranslation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
